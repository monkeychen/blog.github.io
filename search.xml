<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[ZooKeeper Administrator's Guide中文版]]></title>
      <url>%2F2017%2F05%2F08%2FZooKeeper-Administrator-s-Guide%E4%B8%AD%E6%96%87%E7%89%88%2F</url>
      <content type="text"><![CDATA[本文档主要介绍ZooKeeper部署及日常管理 1. 安装部署本章节包含与ZooKeeper部署有关的内容，具体来说包含下面三部分内容： 系统软硬件需求 集群部署（安装） 单机开发环境部署（安装） 前两部分主要介绍如何在数据中心等生产环境上安装部署ZooKeeper，第三部分则介绍如何在非生产环境上（如为了评估、测试、开发等目的）安装部署ZooKeeper。 1.1. 系统软硬件需求1.1.1. 支持的OS平台ZooKeeper框架由多个组件组成，有的组件支持全部平台，而还有一些组件只支持部分平台，详细支持情况如下： Client：它是一个Java客户端连接库，上层应用系统通过它连接至ZooKeeper集群。 Server：它是运行在ZooKeeper集群节点上的一个Java后台服务程序。 Native Client：它是一个用C语言实现的客户端连接库，其与Java客户端库一样，上层应用（非Java实现）通过它连接至ZooKeeper集群。 Contrib：它是指多个可选的扩展组件。 操作系统 Client Server Native Client Contrib GNU/Linux D + P D + P D + P D + P Solaris D + P D + P / / FreeBSD D + P D + P / / Windows D + P D + P / / Mac OS X D D / / D：支持开发环境， P：支持生成环境， /：不支持任何环境 上表中未显式注明支持的组件在相应平台上可能不能正常运行。虽然ZooKeeper社区会尽量修复在未支持平台上发现的BUG，但并无法保证会修复全部BUG。 1.1.2. 软件要求ZooKeeper需要运行在JDK6或以上版本中。若ZooKeeper以集群模式部署，则推荐的节点数至少为3，同时建议部署在独立的服务器上。在Yahoo!，ZooKeeper通常部署在运行RHEL系统的服务器上（服务器配置：双核CPU、2G内存、80G容量IDE硬盘）。 1.2. 集群部署（安装）为了保证ZooKeeper服务的可靠性，您应该以集群模式部署ZooKeeper服务。只要半数以上的集群节点在线，服务将是可用的。因为ZooKeeper需要半数以上节点同意才能选举出Leader，所以建议ZooKeeper集群的节点数为奇数个。举个例子，对于有四个节点的集群只能应付一个节点宕机的异常，如果有两个节点宕机，则剩下两个节点未达到法定的半数以上选票，ZooKeeper服务将变为不可用。而如果集群有五个节点，则集群就可以应付二个节点宕机的异常。 提示：正如《ZooKeeper快速入门》文档中所提到的，至少需要三个节点的ZooKeeper集群才具备容灾特性，因此我们强烈建议集群节点数为奇数。通常情况下，生产环境下，集群节点数只需要三个。但如果为了在服务维护场景下也保证最大的可靠性，您也许会部署五个节点的集群。原因很简单，如果集群节点为三个，当你对其中一个节点进行维护操作，将很有可能因维护操作导致集群异常。而如果集群节点为5个，那你可以直接将维护节点下线，此时集群仍然可正常提供服务（就算四个节点中的任意一个突然宕机）。您的冗余措施应该包括生产环境的各个方面。如果你部署三个节点的ZooKeeper集群，但你却将这三个节点都连接至同一个网络交换机，那么当交换机宕掉时，你的集群服务也一样是不可用的。 关于如何配置服务器使其成为集群中的一个成员节点的详细步骤如下（每个节点的操作类似）： 1.安装JDK，你可以使用本地包管理系统安装，也可以从JDK官网下载 2.设置Java堆相关参数，这对于避免内存swap来说非常重要。因为频繁的swap将严重降低ZooKeeper集群的性能。您可以通过使用压力负载测试来决定一个合适的值，确保该值刚好低于触发swap的阈值。保守的做法是：当节点拥有4G的内存，则设置-xmx=3G。 3.安装ZooKeeper，您可以从官网下载：http://zookeeper.apache.org/releases.html 4.创建一个配置文件，这个文件可以随便命名，您可以先使用如下设置参数： 12345678tickTime=2000dataDir=/var/lib/zookeeper/clientPort=2181initLimit=5syncLimit=2server.1=zoo1:2888:3888server.2=zoo2:2888:3888server.3=zoo3:2888:3888 您可以在配置参数章节中找到上面这些参数及其他参数的解释说明。这里简要说一下：集群中的每个节点都需要知道集群中其它节点成员的连接信息。通过上述配置文件中格式为server.id=host:port:port的若干行配置信息您就可以实现这个目标。host与port意思很简单明了，不多作说明。而server.${id}代表节点ID，你需要为每个节点创建一个名为myid的文件，该文件存放于参数dataDir所指向的目录下。 5.myid文件的内容只有一行，其值为配置参数server.${id}中${id}的实际值。即服务器1对应的myid文件的内容为1，这个值在集群中必须保证其唯一性，同时必须处于[1, 255]之间。 6.如果你已经创建好配置文件（如zoo.cfg），你就可以启动ZooKeeper服务： 123$ java -cp zookeeper.jar:lib/slf4j-api-1.6.1.jar:lib/slf4j-log4j12-1.6.1.jar:lib/log4j-1.2.15.jar:conf \org.apache.zookeeper.server.quorum.QuorumPeerMain zoo.cfg QuorumPeerMain启动一个ZooKeeper服务，JMX管理bean也同时被注册，通过这些JMX管理bean，你就可以在JMX管理控制台上对ZooKeeper服务进行监控管理。ZooKeeper的JMX文档有更详细的介绍信息。同时，你也可以在$ZOOKEEPER_HOME/bin目录下找到ZooKeeper的启动脚本zkServer.sh。 7.接下来你就可以连接至ZooKeeper节点来测试部署是否成功。在Java环境下，你可以运行下面的命令连接至已启动的ZooKeeper服务节点并执行一些简单的操作 1$ bin/zkCli.sh -server 127.0.0.1:2181 1.3. 单机开发环境部署介绍如果你想部署ZooKeeper以便于开发测试，那你可以使用单机部署模式。然后安装Java或C客户端连接库，同时在配置文件中将服务器信息与开发机绑定。具体安装部署步骤也集群部署模式类似，唯一不同的是zoo.cfg配置文件更简单一些。你可以从《ZooKeeper快速入门》文档中的相关章节获取详细的操作步骤。关于安装客户端连接库的相关信息，你可以从ZooKeeper Programmer’s Guide文件的Bindings章节中获取。 2. 维护管理这部分包含ZooKeeper运行与维护相关的信息，其包含如下几个主题： ZooKeeper集群部署规划 Provisioning Things to Consider: ZooKeeper Strengths and Limitations Administering Maintenance Supervision Monitoring Logging Troubleshooting Configuration Parameters ZooKeeper Commands: The Four Letter Words Data File Management Things to Avoid Best Practices 2.1. ZooKeeper集群部署规划ZooKeeper可靠性依赖于两个基本的假设： 一个集群中只会有少数服务器会出错，这里的出错是指宕机或网络异常而使得服务与集群中的多数服务器失去联系。 已部署的机器可以正常运行，所谓正常运行是指所有代码可以正确的执行，有适当且一致的工作时钟、存储、网络。 为了最大可能的保证上述两个前提假设能够成立，这里有几个点需要考虑。一些是关于跨服务器（节点之间）需求的，而另一些是关于集群中每个节点服务器的考虑]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JVM方法区(PermGen)内存快速飙升问题]]></title>
      <url>%2F2017%2F05%2F07%2FJVM%E6%96%B9%E6%B3%95%E5%8C%BA-PermGen-%E5%86%85%E5%AD%98%E5%BF%AB%E9%80%9F%E9%A3%99%E5%8D%87%E9%97%AE%E9%A2%98%2F</url>
      <content type="text"><![CDATA[1. 问题描述自从平台升级到3.0后，应用的JVM变得非常不稳定，主要体现为以下三个问题： 内存泄漏：2G的JVM，2天就崩。 方法区内存持续飙升，最终导致频繁的触发FullGC class load频繁导致CPU有30%的资源浪费 2. 解决方案2.1. 问题1解决思路：问题1相对好解决，先用jmap将堆快照dump出来，用mat分析了下，根据GC-ROOT找到引用路径即可，泄漏原因为：平台自研JPA组件的SQLQuery在实现lazy load时，由于CGLib使用不当(在向当前线程注册回调方法拦截器时，在使用完之后未及时注销)导致的查询结果缓存被线程池中的线程引用，在线程池容量开得比较大时最终将导致OOM异常。 2.2. 问题2,3解决思路：以前从没碰到这种情况，方法区的内存大小在应用启动后应该是处于一个相对稳定的状态（因为大部分类在启动时就已经加载完了，就算使用CGLib动态生成代理类也应该是有一个上限，最多就是全部类的一倍），但问题2明显不属于这种情况，不管开多大的内存给方法区（通过-X:MaxPermSize=xxxM设置大小），应用总能在几分钟内持续升到最高值并触发FullGC，GC结束后，方法区占用内存降至接近0M（此处就发生的class unload），然后又进入新一轮的飙升周期（此处就发生class loader）。 刚开始以为仍然是JPA组件使用CGLib不当的问题，认为是为了实现lazy load及权限控制时使用了过多的动态代理（每个Action,Model,Service都被创建为动态代理，更不合理的时每个model的get方法都使用ProxyMethodInterceptor，问当事人原因，其答复说为了lazy load，但其实只有关联字段，集合字段才有必要lazy load）。基于此做了修改，但测试结果还是没解决问题：因为JPA中并不是每次都创建一个新的proxy，而是根据class做了缓存的，因此只能另找办法。 既然是方法区的问题，那是否可以将方法区的内容dump出来呢？于是查看了下jmap参数，其中的有-permstat可以用：jmap -permstat &lt;pid&gt;结果如下（截取） 1234567891011121325007 intern Strings occupying 2799672 bytes. class_loader classesbytes parent_loaderalive? type &lt;bootstrap&gt; 262415108248 null live &lt;internal&gt; 0x000000076f045910 38758792 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x000000076f942f10 38758792 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x00000007d00e9ba0 40816816 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x00000007dd170c08 40816816 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x000000079e2f0070 40816816 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x00000007cd6b1140 13112 null dead sun/reflect/DelegatingClassLoader@0x0000000740067648 0x000000076fb5d130 38758792 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 0x000000076fbe47c0 38758792 0x00000007617d4f70dead com/atomikos/util/ClassLoadingHelper$1@0x0000000741cb86e8 com/atomikos/util/ClassLoadingHelper$1：是一个匿名内部类（该类是一个加载器），通过这个内部类加载器作为JDK Proxy.newProxyInstance()方法的参数，而后者就会生产大量的以Proxy$为前缀的动态类，并且未做任何缓存。atomikos大家应该都很清楚：JTA的一个实现，但是哪个组件调用了这个工具类呢？通过断点分析，原来是JPA又自己写了个什么数据库连接池，池中的每个连接都是ProxyConnection，而池又好像失效的，频繁的回收，创建… 到目前为止，我一直没搞清楚为何要用代理类型的连接，这代理的作用从代码中也没看出个门道来，也不是为做监控。 原因定位到了，解决办法就很简单了：直接用阿里的druid替换掉。测试结果证明前面的分析是正确的。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[HA专题--Pacemaker集群日常管理命令]]></title>
      <url>%2F2017%2F04%2F29%2FHA%E4%B8%93%E9%A2%98-Pacemaker%E6%97%A5%E5%B8%B8%E7%AE%A1%E7%90%86%E5%91%BD%E4%BB%A4%2F</url>
      <content type="text"><![CDATA[概述Pacemaker的管理工具主要有两种：crmsh、pcs(Pacemaker/Corosync configuration system)，本文将同时介绍这两种命令行工具。 从CentOS6.4以后开始采用PCS替代crmsh来管理pacemaker集群（PCS专用于pacemaker+corosync的设置工具，其有CLI和web-based GUI界面）文档来源于Pacemaker的Github官网 通用操作显示配置信息以XML格式显示 1234# crmsh crm configure show xml# pcs pcs cluster cib 以非XML格式显示[To show a simplified (non-xml) syntax] 1234# crmshcrm configure show# pcspcs config 显示集群当前状态1234# crmshcrm status#pcspcs status 也可以这样： 1crm_mon -1 挂起节点（Node standby）使节点进入Standby状态（Put node in standby） 1234# crmshcrm node standby pcmk-1# pcspcs cluster standby pcmk-1 使节点从Standby状态恢复（Remove node from standby） 1234# crmshcrm node online pcmk-1# pcspcs cluster unstandby pcmk-1 crm has the ability to set the status on reboot or forever.pcs can apply the change to all the nodes. 设置集群全局属性1234# crmshcrm configure property stonith-enabled=false# pcspcs property set stonith-enabled=false 集群资源处理操作列出所有RA(Resource Agent)的类别:classes1234# crmshcrm ra classes# pcspcs resource standards 列出所有可用的RA123456789101112# crmshcrm ra list ocfcrm ra list lsbcrm ra list servicecrm ra list stonith# pcspcs resource agents ocfpcs resource agents lsbpcs resource agents servicepcs resource agents stonithpcs resource agents 您也可以通过provider进一步过滤： 1234# crmshcrm ra list ocf pacemaker# pcspcs resource agents ocf:pacemaker 查询具体RA的描述信息1234# crmshcrm ra meta IPaddr2# pcspcs resource describe IPaddr2 Use any RA name (like IPaddr2) from the list displayed with the previous commandYou can also use the full class:provider:RA format if multiple RAs with the same name are available : 1234# crmshcrm ra meta ocf:heartbeat:IPaddr2# pcspcs resource describe ocf:heartbeat:IPaddr2 创建资源123456# crmshcrm configure primitive ClusterIP ocf:heartbeat:IPaddr2 \ params ip=192.168.122.120 cidr_netmask=32 \ op monitor interval=30s # pcspcs resource create ClusterIP IPaddr2 ip=192.168.0.120 cidr_netmask=32 The standard and provider (ocf:heartbeat) are determined automatically since IPaddr2 is unique.The monitor operation is automatically created based on the agent’s metadata. 显示资源配置信息1234# crmshcrm configure show# pcspcs resource show crmsh also displays fencing resources.The result can be filtered by supplying a resource name (IE ClusterIP): 1234# crmshcrm configure show ClusterIP# pcspcs resource show ClusterIP crmsh also displays fencing resources. 显示fencing资源1234# crmshcrm resource show# pcspcs stonith show pcs treats STONITH devices separately. 显示Stonith资源代码(RA)信息1234# crmshcrm ra meta stonith:fence_ipmilan# pcspcs stonith describe fence_ipmilan 启动资源1234# crmshcrm resource start ClusterIP# pcspcs resource enable ClusterIP 停止资源1234# crmshcrm resource stop ClusterIP# pcspcs resource disable ClusterIP 删除资源1234# crmshcrm configure delete ClusterIP# pcspcs resource delete ClusterIP 更新资源1234# crmshcrm resource param ClusterIP set clusterip_hash=sourceip# pcspcs resource update ClusterIP clusterip_hash=sourceip crmsh also has an edit command which edits the simplified CIB syntax(same commands as the command line) via a configurable text editor. 12# crmshcrm configure edit ClusterIP Using the interactive shell mode of crmsh, multiple changes can beedited and verified before committing to the live configuration. 12345# crmshnode-01$ crm configure # 进入crmsh上下文模式crm(live)configure$ editcrm(live)configure$ verifycrm(live)configure$ commit 删除给定资源上的属性信息1234# crmshcrm resource param ClusterIP delete nic# pcspcs resource update ClusterIP ip=192.168.0.98 nic= 列出资源的默认属性信息1234# crmshcrm configure show type:rsc_defaults# pcspcs resource defaults 设置资源的默认属性信息1234# crmshcrm configure rsc_defaults resource-stickiness=100# pcspcs resource defaults resource-stickiness=100 列出资源操作命令相关属性的默认值1234# crmshcrm configure show type:op_defaults# pcspcs resource op defaults 设置资源操作命令相关属性的默认值1234# crmshcrm configure op_defaults timeout=240s# pcspcs resource op defaults timeout=240s 设置Colocation约束1234# crmshcrm configure colocation website-with-ip INFINITY: WebSite ClusterIP# pcspcs constraint colocation add ClusterIP with WebSite INFINITY With roles 1234# crmshcrm configure colocation another-ip-with-website inf: AnotherIP WebSite:Master# pcspcs constraint colocation add Started AnotherIP with Master WebSite INFINITY 设置ordering约束1234# crmshcrm configure order apache-after-ip mandatory: ClusterIP WebSite# pcspcs constraint order ClusterIP then WebSite With roles: 1234# crmshcrm configure order ip-after-website Mandatory: WebSite:Master AnotherIP# pcspcs constraint order promote WebSite then start AnotherIP 设置preferred location约束1234# crmshcrm configure location prefer-pcmk-1 WebSite 50: pcmk-1# pcspcs constraint location WebSite prefers pcmk-1=50 With roles: 1234# crmshcrm configure location prefer-pcmk-1 WebSite rule role=Master 50: \#uname eq pcmk-1# pcspcs constraint location WebSite rule role=master 50 \#uname eq pcmk-1 移动资源至指定节点（Move resources）12345crm resource move WebSite pcmk-1pcs resource move WebSite pcmk-1 crm resource unmove WebSitepcs resource clear WebSite A resource can also be moved away from a given node: 12crm resource ban Website pcmk-2pcs resource ban Website pcmk-2 Remember that moving a resource sets a stickyness to -INF to a given node until unmoved Resource tracing12crm resource trace Website# pcs不支持 清理指定资源的失败计数信息（Clear fail counts）12crm resource cleanup Websitepcs resource cleanup Website 编辑Edit fail counts1234crm resource failcount Website show pcmk-1crm resource failcount Website set pcmk-1 100 # pcs不支持 Handling configuration elements by typepcs deals with constraints differently. These can be manipulated by the command above as well as the following and others 123# 下面这行命令的list可以省略，使用full选项是为了显示相关的idpcs constraint list --full pcs constraint remove cli-ban-Website-on-pcmk-1 使用crmsh命令删除约束的方式与删除资源的命令一样Removing a constraint in crmsh uses the same command as removing a resource. 1crm configure remove cli-ban-Website-on-pcmk-1 The show and edit commands in crmsh can be used to manageresources and constraints by type: 12crm configure show type:primitivecrm configure edit type:colocation Create a clone12crm configure clone WebIP ClusterIP meta globally-unique=true clone-max=2 clone-node-max=2pcs resource clone ClusterIP globally-unique=true clone-max=2 clone-node-max=2 Create a master/slave clone123456crm configure ms WebDataClone WebData \ meta master-max=1 master-node-max=1 \ clone-max=2 clone-node-max=1 notify=truepcs resource master WebDataClone WebData \ master-max=1 master-node-max=1 \ clone-max=2 clone-node-max=1 notify=true 其它操作批量修改配置信息1234567891011121314151617# crmsh通过crm命令进入crmsh上下文模式，直接对CIB文档结构进行操作，最后再一次性commitcrmsh # crmcrmsh # cib new drbd_cfgcrmsh # configure primitive WebData ocf:linbit:drbd params drbd_resource=wwwdata \ op monitor interval=60scrmsh # configure ms WebDataClone WebData meta master-max=1 master-node-max=1 \ clone-max=2 clone-node-max=1 notify=truecrmsh # cib commit drbd_cfgcrmsh # quit# pcs则先基于本地文件方式批量设置CIB参数，然后再通过push操作使配置生效pcs # pcs cluster cib drbd_cfgpcs # pcs -f drbd_cfg resource create WebData ocf:linbit:drbd drbd_resource=wwwdata \ op monitor interval=60spcs # pcs -f drbd_cfg resource master WebDataClone WebData master-max=1 master-node-max=1 \ clone-max=2 clone-node-max=1 notify=truepcs # pcs cluster push cib drbd_cfg 创建模板（Template creation）Create a resource template based on a list of primitives of the sametype 1crm configure assist template ClusterIP AdminIP 日志分析Display information about recent cluster events 1234crmsh # crm historycrmsh # peinputscrmsh # transition pe-input-10crmsh # transition log pe-input-10 Configuration scriptsCreate and apply multiple-step cluster configurations includingconfiguration of cluster resources 1234567crmsh # crm script show apachecrmsh # crm script run apache \ id=WebSite \ install=true \ virtual-ip:ip=192.168.0.15 \ database:id=WebData \ database:install=true]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java小问题汇总]]></title>
      <url>%2F2016%2F11%2F09%2FJava%E5%B0%8F%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
      <content type="text"><![CDATA[1. MySQL5.7下的JSON字段中文乱码问题中文乱码问题在Java Web开发中经常碰到，大部分原因是后端与前端的编码不一致造成的（如tomcat的默认编码为ISO-8859-1，而前端为GBK），解决办法也简单，只需要加一个CharsetEncodingFilter就行。但本文要讲的不是这一类总是，而是纯粹的后端问题。 1.1 环境准备 假设MySQL的默认CharSet为UTF-8，应用及部署环境也为UTF-8 创建包含JSON字段的数据库表 12345678CREATE TABLE "ipms_device_feature" ( "ID" int(11) NOT NULL AUTO_INCREMENT, "DEVICE_SERIAL_NUMBER" varchar(100) NOT NULL DEFAULT '' COMMENT '设备SN', "DEVICE_IP" varchar(32) NOT NULL DEFAULT '' COMMENT '设备IP', "FEATURES" json DEFAULT NULL COMMENT '设备巡检指标集', "UPDATETIME" timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间', PRIMARY KEY ("ID")) 运行如下脚本查看字段详细信息 1show full fields from ipms_device_feature 结果如下： 上图中features这个字段的Collation列为Null 12# 使用如下SQL时，JDBC在解析返回的数据（包含中文）时会出现乱码select features from ipms_device_feature 解决办法 第一步：使用MySQL提供的json_unquote方法 1select json_unquote(features) as features from ipms_device_feature 第二步：在Java中调用上面的SQL时，将会返回一个byte数组，因此只需要通过String提供的方法进行转码就行。 12345List&lt;Map&gt; rows = em.createNamedQuery("XXX").list();for(Map row : rows) &#123; byte[] bytes = (byte[]) row.get("features"); String features = new String(bytes, "UTF-8");&#125; 这样的话，Java变更features就是正常的中文，就可以直接回传给前端页面了。 2. 几个容易踩的坑2.1. Integer对象之间比较的坑对于Integer var=?在-128至127之间的赋值，Integer 对象是在IntegerCache.cache产生，会复用已有对象，这个区间内的Integer值可以直接使用==进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象。因此建议Integer对象在比较时应使用equals方法。 2.2. ArrayList的subList()方法返回值的坑ArrayList的subList方法返回的结果不可强转成ArrayList，否则会抛出ClassCastException异常： 1java.util.RandomAccessSubList cannot be cast to java.util.ArrayList; 因为subList方法返回的是ArrayList的内部类SubList，并不是ArrayList，而是ArrayList的一个视图，对于内部类SubList的所有操作最终会反映到原列表上。 2.3. Arrays.asList()方法返回值的坑使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的 add/remove/clear方法会抛出UnsupportedOperationException异常。因为asList方法的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。 1234String[] str = new String[] &#123; "a", "b" &#125;;List list = Arrays.asList(str);list.add("c"); // 运行时异常。str[0]= "gujin"; // 则list.get(0)也会随之修改。 3. 待续… 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Composer学习笔记]]></title>
      <url>%2F2016%2F09%2F01%2FComposer%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
      <content type="text"><![CDATA[#Composer学习笔记 一、安装(MacOS) 系统要求：PHP5.3.2+以上版本学习参考：Composer官方文档 Composer安装分两种： 1.局部安装将composer.phar文件内嵌于PHP应用目录下，命令如下： 1234php -r "copy('https://getcomposer.org/installer', 'composer-setup.php');"php -r "if (hash_file('SHA384', 'composer-setup.php') === 'e115a8dc7871f15d853148a7fbac7da27d6c0030b848d9b3dc09e2a0388afed865e6a3d6b3c0fad45c48e2b5fc1196ae') &#123; echo 'Installer verified'; &#125; else &#123; echo 'Installer corrupt'; unlink('composer-setup.php'); &#125; echo PHP_EOL;"php composer-setup.phpphp -r "unlink('composer-setup.php');" 以上命令分别做如下几件事件： 下载安装器 校验 执行安装 删除安装器 安装完成后，会在当前工作目录下生成可执行文件：composer.phar，你可以通过如下方式使用（运行）composer来进行项目的依赖管理： 12php composer.phar &lt;command&gt;# command指install等composer命令 2.全局安装将可执行二进制文件放在系统PATH路径下，命令如下： 1234# 假设局部安装中生成的composer.phar文件在当前目录下# /usr/local/bin/目录是一个现成的PATH目录，# 你也可以将可执行文件放置于其他PATH目录下mv composer.phar /usr/local/bin/composer 通过这种方式，你就可以直接按如下方式来使用composer： 12composer &lt;command&gt;# command指install等composer命令 二、基本概念1. composer.json文件每个基于Composer的项目都需要包含composer.json文件，该文件用于声明项目所依赖的第三方库，其为JSON文件，格式类似： 12345&#123; "require": &#123; "monolog/monolog": "1.2.*" &#125;&#125; require属性是用于声明依赖信息的地方。 当运行composer install安装依赖时，Composer会将依赖库下载到项目根目录的vendor目录下。如monolog依赖安装后，其存放在vendor\monolog\monolog目录下。 2. composer.lock文件当执行如下命令安装依赖后，Composer将会在项目目录下创建composer.lock文件。 1composer install Composer将把安装时确切的版本号列表写入composer.lock文件。这将锁定改项目的特定版本。后续再次运行composer install时，Composer将先检查目录下是否有composer.lock，若有则直接忽略composer.json，而使用composer.lock中的确切的版本信息。团队成员可以共享该lock文件以解决版本不一致问题。当依赖版本有升级时，若想更新依赖至最新版本可以运行如下命令 1234# 全部更新composer update# 只更新某个依赖库composer update monolog/monolog [...] 3. 自动加载对于库的自动加载信息，Composer 生成了一个vendor/autoload.php文件。通过引入这个文件，就实现了自动加载功能。 1require 'vendor/autoload.php'; 通过自动加载功能我们可以很容易的使用第三方代码。例如：项目依赖monolog，我们就可以像这样开始使用这个类库，并且他们将被自动加载。 1234$log = new Monolog\Logger('name');$log-&gt;pushHandler(new Monolog\Handler\StreamHandler('app.log', Monolog\Logger::WARNING));$log-&gt;addWarning('Foo'); 当然，我们也可以在composer.json的autoload字段中增加自己的autoloader。 12345&#123; "autoload": &#123; "psr-4": &#123;"Acme\\": "src/"&#125; &#125;&#125; Composer将注册一个PSR-4 autoloader到Acme命名空间。 你可以定义一个从命名空间到目录的映射。此时src会在你项目的根目录，与vendor文件夹同级。例如src/Foo.php文件应该包含Acme\Foo类。 添加autoload字段后，你应该再次运行install命令来生成 vendor/autoload.php文件。 引用这个文件也将返回autoloader的实例，你可以将包含调用的返回值存储在变量中，并添加更多的命名空间。这对于在一个测试套件中自动加载类文件是非常有用的，例如： 12$loader = require 'vendor/autoload.php';$loader-&gt;add('Acme\\Test\\', __DIR__); 三、库不重复造轮子，这是大伙天天喊的，因为社区已经为大伙提供了很多可直接引用的轮子，这些轮子的学名就叫“库”。如果你觉得自己的项目可以帮到别人，你可以选择将其打包成库，并大告天下。你只要按如下步骤操作就行： 为项目的composer.json添加name属性 [必需] 发布至git等版本管理系统或packagist composer.json中还有一个version属性，但一般不建议设置，因为composer会根据tag标签自行推算版本号，如果项目代码为master，则版本会被推算为dev-master packagist可理解为一个公共的组件仓库，类似maven中央库 对于未发布至packagist库的组件，引用方需要指定repositories 比如，假如我们将项目发布至Github下，项目的composer.json如下： 123456&#123; "name": "simiam/composer-demo", "require": &#123; "monolog/monolog": "1.0.*" &#125;&#125; 接下来，我们的另一个项目blog需要引用上面发布的simiam/composer-demo组件，则blog项目的composer.json内容如下： 123456789101112&#123; "name": "simiam/blog", "repositories": [ &#123; "type": "vcs", "url": "https://github.com/monkeychen/simiam" &#125; ], "require": &#123; "simiam/composer-demo": "dev-master" &#125;&#125; 因为我们发布的是master分支，所以require中依赖的版本号为dev-master如果组件已经发布至packagist的话，则不需要声明repositories，因为composer默认会从中央库中搜索。 更详细的信息，可以参考这里。 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[MAC下搭建Apache+PHP开发环境]]></title>
      <url>%2F2016%2F07%2F02%2FMAC%E4%B8%8B%E6%90%AD%E5%BB%BAApache%2BPHP%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
      <content type="text"><![CDATA[apache配置文件为：/etc/apache2/httpd.conf OSX下默认集成了apache与php； Mac Apache 有2个默认的网站目录，一个是/Library/WebServer/Documents/，一个是用户目录下的Sites目录（推荐使用），默认未开启； Apache 基本命令： 123启动:sudo apachectl start停止:sudo apachectl stop重启:sudo apachectl restart 1. 配置apacheStep 1. 在用户目录下用Finder创建 Sites 文件夹； Step 2. 在/etc/apache2/users/目录下添加 username.conf文件(username要替换成真正的用户名，下同)： 12cd /etc/apache2/users sudo vim username.conf Step 3. 在username.conf文件中添加如下内容： Step 4. 检查username.conf文件的权限是否正确，正确的应该为： 1-rw-r--r-- 1 root wheel 126 Mar 23 23:02 username.conf 如果不是，则需要修改权限，使用如下命令： 1sudo chmod 644 username.conf Step 5. 修改httpd.conf文件配置： 1sudo vim /etc/apache2/httpd.conf 在httpd.conf找到如下3行，并确保这3行的注释＃是被删除的 123LoadModule authz_core_module libexec/apache2/mod_authz_core.soLoadModule authz_host_module libexec/apache2/mod_authz_host.soLoadModule userdir_module libexec/apache2/mod_userdir.so 接着启用用户目录配置，同为删除对应行的＃ 1Include /private/etc/apache2/extra/httpd-userdir.conf Step 6. 修改httpd-userdir.conf文件配置 1sudo vim /etc/apache2/extra/httpd-userdir.conf 取消如下行的＃ 1Include /private/etc/apache2/users/*.conf Step 7. 重启Apache，并检查配置是否生效 1sudo apachectl restart 在浏览器输入：http://localhost/~username/，看是否配置成功 Step 8. 让apache支持php脚本 修改 httpd.conf 文件配置 1sudo vim /etc/apache2/httpd.conf 取消php库文件的＃注释 1LoadModule php5_module libexec/apache2/libphp5.so 重启Apache 1sudo apachectl restart 在Sites目录下创建index.php，内容如下： 1&lt;?php phpinfo(); ?&gt; 在浏览器里输入：http://localhost/~username 如果能显示php环境信息，则说明php环境搭建成功 Step 9. 配置虚拟主机(vhost) 将/etc/apache2/httpd.conf文件中如下内容的#去掉 1#Include /private/etc/apache2/extra/httpd-vhosts.conf 修改/etc/apache2/extra/httpd-vhosts.conf: 1234567891011121314151617181920212223242526272829&lt;VirtualHost *:80&gt; ServerAdmin admin@simiam.vhost.com DocumentRoot "/Users/chenzhian/workspace/php/website/public" ServerName simiam.vhost.com DirectoryIndex main.php index.php index.html &lt;Directory "/Users/chenzhian/workspace/php/website/public"&gt; Options FollowSymLinks Multiviews MultiviewsMatch Any AllowOverride All Require all granted &lt;/Directory&gt; ErrorLog "/private/var/log/apache2/simiam.vhost.com-error_log" CustomLog "/private/var/log/apache2/simiam.vhost.com-access_log" common&lt;/VirtualHost&gt;&lt;VirtualHost *:80&gt; ServerAdmin admin@100.vhost.com DocumentRoot "/Users/chenzhian/workspace/php/website/100" ServerName 100.vhost.com DirectoryIndex index.php index.html &lt;Directory "/Users/chenzhian/workspace/php/website/100"&gt; Options FollowSymLinks Multiviews MultiviewsMatch Any AllowOverride All Require all granted &lt;/Directory&gt; ErrorLog "/private/var/log/apache2/100.vhost.com-error_log" CustomLog "/private/var/log/apache2/100.vhost.com-access_log" common&lt;/VirtualHost&gt; 2. 修改或创建php.iniStep 1. 为了开启php的一些扩展功能，有必要对php.ini进行修改。OSX默认提供的php是没有php.ini文件的，因此我们需要自己创建一个。可以在/etc/目录下创建php.ini /etc/目录下有提供php.ini.default模板 1sudo cp /etc/php.ini.default /etc/php.ini 如果不知道php默认是到哪里找php.ini文件的话，则使用命令php --ini： 命令输出如下类似信息： 1234Configuration File (php.ini) Path: /etcLoaded Configuration File: /etc/php.iniScan for additional .ini files in: /Library/Server/Web/Config/phpAdditional .ini files parsed: (none) Step 2. 在php.ini文件最后添加如下内容以启用xdebug扩展: 123456789101112[xdebug]zend_extension=/usr/lib/php/extensions/no-debug-non-zts-20121212/xdebug.soxdebug.remote_autostart=onxdebug.remote_enable=onxdebug.remote_enable=1xdebug.remote_mode="req"xdebug.remote_log="/var/log/xdebug.log"xdebug.remote_host=127.0.0.1xdebug.remote_port=9000xdebug.remote_handler="dbgp"xdebug.idekey="PhpStorm" xdebug.remote_host的值建议设置为127.0.0.1，而不要设置为localhost（当开启调试模式时，可能会出现域名解析很慢的问题） 3. 安装并配置PhpStormStep 1. 配置php解释器:直接在Preferences的Languages-&gt;PHP页面添加php命令路径: 1/usr/bin/php Step 2. 配置debug 在PHP-&gt;Debug-&gt;DBGp中添加如下信息: 123IDE key:PhpStorm (与php.ini中xdebug配置项xdebug.idekey一致) Host:localhost (apache服务地址) Port:80 (apache服务端口) 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[JNI引起的堆外内存泄漏问题分析]]></title>
      <url>%2F2016%2F02%2F27%2FJNI%E5%BC%95%E8%B5%B7%E7%9A%84%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[背景客户现场的监控系统中有一个网络听诊器功能，其每隔1分钟会对全网设备进行ping操作，以此来尽可能快的发现设备及网络是否出现异常。暂且不说通过该功能来对设备及网络作健康检测是否靠谱。由于JAVA对于网络层以下的协议是无能为力的，而ping操作涉及ICMP与ARP协议，因此监控系统只能借助JNI机制来搞定。 BUG现象监控系统的java.exe进程每隔几个小时就异常退出 问题定位 通过应用系统的日志看是否为业务相关的异常引起的 –》日志中并无任何异常信息 打开GC日志，并观察一段时间，看是否存在堆内存回收异常（泄漏或溢出） –》堆内存一切正常 此时忽然想起，java.exe进程异常退出应该会生成相关的hs_err.log文件，果然在应用目录下找到了一堆错误文件。该日志也叫crash日志。 通过查看hs_err.log内容得知，原来是jni ping引入的dll调用异常导致java.exe进程异常中止了。 PS：如果能早点想起步骤3，那就不用浪费步骤2的功夫了。 JNI调用异常分析JNI异常导致java进程中止的原因可能为 JVM自己的BUG：谷歌了一把，网上描述的BUG中，现场的JDK版本都已经修复了。 JNI DLL的BUG：这个原因范围就大了，至此只能根据经验猜测可能的原因，然后一个一个排除了。 由于linux环境下有这么一个机制：当内核检测到进程的物理内存不断增加至某一个值时，内核会直接将该进程kill掉。 windows是否也有这样的机制呢？目前尚未查证，还请高手解答。 在没有进一步证据的前提下，只能先猜测是否为进程物理内存出了问题，于是监测了下应用进程的物理内存损耗量，果然是缓慢递增的，但JVM堆内存仍然一切正常，由此大约知道是堆外内存使用上出了问题。 关于堆外内存的相关知识，可参考下面的文章： 进程物理内存远大于Xmx的问题分析 JVM源码分析之堆外内存完全解读 至此，可以知道该问题与JAVA没啥关系了，但为了彻底搞明白，我还是硬着头皮找来DLL的C源码，想看看是否可以用我helloworld级别的C水平把这个问题搞定。 堆外内存[泄漏、异常]分析分析C/C++应用的内存，大伙一般都会想到perftool，可惜windows环境下我始终编译不过。于是谷歌上再搜索一把”windows内存泄漏”，发现知乎上有文章推荐了一堆，但我要么下载不到，要么看不懂。最后是根据《C/C++内存泄漏及检测》介绍的方法定位到是dll中有一段代码使用了缓存导致内存泄漏，当内存达到JVM中设置的MaxDirectMemorySize值时，dll就会出现内存访问异常错误，最终导致java.exe进程异常退出了。 PS：在定位堆外内存异常相关问题时，为了快速重现问题，可以将MaxDirectMemorySize改小，MaxDirectMemorySize的默认值可认为与-Xmx设置的值一样（严格上不是，参见JVM源码分析之堆外内存完全解读） 总结该问题并非通用性问题，写这篇文章主要是为了记录下当时解决该问题的整个定位过程，文中一些知识点可能表述有误，还请批评指正。 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Laravel 5.2中文文档：HTTP路由]]></title>
      <url>%2F2016%2F01%2F21%2FLaravel-5-2%E4%B8%AD%E6%96%87%E6%96%87%E6%A1%A3%EF%BC%9AHTTP%E8%B7%AF%E7%94%B1%2F</url>
      <content type="text"><![CDATA[基本路由所有的Laravel路由规则都定义在app/Http/routes.php文件中，Laravel框架在初始化时将自动加载该文件。Laravel中最基本的路由规则如下： Route::get(&apos;foo&apos;, function () { return &apos;Hello World&apos;; }); 其接受两个参数：匹配该路由的URI、路由处理闭包Closure；该闭包定义了具体的路由规则。 默认路由文件 默认情况下，routes.php中可以定义简单的路由，或者将这些路由定义在路由组中。路由组将利用web中间件为定义在其中的路由规则提供’会话状态’与CSRF保存等功能。 任何未放在路由组中的路由规则将无权访问会话，也无法享受web中间件提供的CSRF保护等特性，因此如果您定义的路由规则需要web中间件提供的这些特性时，你需要确保将这些路由规则放入路由组中；通过情况下，我们会将大部分的路由规则都放在路由组中。 Route::group([&apos;middleware&apos; =&gt; [&apos;web&apos;]], function () { // }); Route类中可用的路由方法 框架路由引擎允许你注册如下的路由规则来响应相应的HTTP请求动作： Route::get($uri, $callback); Route::post($uri, $callback); Route::put($uri, $callback); Route::patch($uri, $callback); Route::delete($uri, $callback); Route::options($uri, $callback); 有时你需要注册一个路由规则来响应多个HTTP请求动作，因此你可以使用Route类的match方法来满足该需求。甚至你可以使用Route类的any方法来响应所有的HTTP请求动作。 Route::match([&apos;get&apos;, &apos;post&apos;], &apos;/&apos;, function () { // }); Route::any(&apos;foo&apos;, function () { // }); 路由参数(占位符)Laravel中路由规则配置中的URL中允许设置参数(占位符)，便于闭包或控制器方法提取与引用。Laravel的路由URL中参数占位符配置方式分两种：必选与可选。 这种机制蛮适合开发符合RESTful规范的应用，这里有一篇由《黑客与画家》、《软件随想录》译者阮一峰写的介绍RESTful概念的文章： 理解RESTful架构 必选参数占位符 所谓必选，即HTTP请求的URL中参数占位符的部分必需有具体的数据，否则该路由规则不会被匹配到。比如，你可能需要从请求URL中获取用户的ID时，你就可以定义如下的路由规则： Route::get(&apos;user/{id}&apos;, function ($id) { return &apos;User &apos;.$id; }); // 当请求URL为http://somesite/user/2时，2将被提取出来并赋值给闭包函数中的变量id 由上面的例子可知，路由参数占位符是由一对花括号来定义的。当然，我们也可以在URL中定义多个参数占位符，如下： Route::get(&apos;posts/{post}/comments/{comment}&apos;, function ($postId, $commentId) { // }); 注意：路由参数占位符的定义需要符合PHP变量命名规范，如不能包含”-“符。 可选参数占位符 如果想让路由参数占位符是可选的（有时请求URL中的占位符部分可能是空的），此时可以在占位符名称的后面加上一个问号”?”即可。 Route::get(&apos;user/{name?}&apos;, function ($name = null) { return $name; }); Route::get(&apos;user/{name?}&apos;, function ($name = &apos;John&apos;) { return $name; }); 当URL参数占位符设置为可选时，后面的闭包函数的参数需要提供默认值。 命名路由命名路由将允许你方便的生成URL或重定向URL，这些生成的URL最终将匹配该路由规则。你可通过如下方式定义命名路由： Route::get(&apos;profile&apos;, [&apos;as&apos; =&gt; &apos;profile&apos;, function () { // }]); 闭包函数的第二个数组参数的元素键值需要指定为”as”，元素值即为路由规则名。当然，你也可以为控制器的方法来代替上面的闭包函数，如下： Route::get(&apos;profile&apos;, [ &apos;as&apos; =&gt; &apos;profile&apos;, &apos;uses&apos; =&gt; &apos;UserController@showProfile&apos; ]); 定义命名路由还有如下方式： Route::get(&apos;user/profile&apos;, &apos;UserController@showProfile&apos;)-&gt;name(&apos;profile&apos;); 即先定义一个普通路由，然后再调用该路由规则实例的name方法。 路由组与命名路由 如果你正在使用路由规则组时，你可以在路由规则组定义的属性数组中添加一个key为”as”，值为某字符串的元素，该元素的值将作为该路由组中包含的路由名字的前缀。如下： Route::group([&apos;as&apos; =&gt; &apos;admin::&apos;], function () { Route::get(&apos;dashboard&apos;, [&apos;as&apos; =&gt; &apos;dashboard&apos;, function () { // Route named &quot;admin::dashboard&quot; }]); }); 生成匹配命名路由的URL 一旦你已经为某一路由起了相应的名字，那么你就可以通过全局函数route来生成相应的URL： // Generating URLs... $url = route(&apos;profile&apos;); // Generating Redirects... return redirect()-&gt;route(&apos;profile&apos;); 如果命名路由规则的URL部分包含参数占位符，则你可以将参数值作为route函数的第二个数组参数的元素传入，框架将自动用该参数值代替占位符以生成相应的URL。 Route::get(&apos;user/{id}/profile&apos;, [&apos;as&apos; =&gt; &apos;profile&apos;, function ($id) { // }]); $url = route(&apos;profile&apos;, [&apos;id&apos; =&gt; 1]); 路由组 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Java调试工具:JDB]]></title>
      <url>%2F2016%2F01%2F13%2FJava%E8%B0%83%E8%AF%95%E5%B7%A5%E5%85%B7-JDB%2F</url>
      <content type="text"><![CDATA[代码调试是大家在日常应用开发定位BUG时会经常使用的技能。然而在客户生产环境下，一没有开发环境，二没有外网连接，如果此时应用出问题，而通过日志又无法定位时，该怎么办呢？ 也许有人会按如下步骤来定位问题（假设BUG可复现且客户允许应用服务重启）： 在本地可能出问题的相关代码中添加许多的日志信息，以将应用运行状态打印出来。 打包并部署至客户现场环境 复现BUG并查看日志信息并最终解决问题 其实JDK中提供的JDB是一个更加理想现场调试工具，其包含的命令列表如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596** JDB命令列表 **connectors -- 列出此 VM 中可用的连接器和传输器run [类 [参数]] -- 开始执行应用程序的主类threads [线程组] -- 列出线程thread &lt;线程 ID&gt; -- 设置默认线程suspend [线程 ID] -- 暂停线程（默认值为 all）resume [线程 ID] -- 恢复线程（默认值为 all）where [&lt;线程 ID&gt; | all] -- 转储线程的堆栈wherei [&lt;线程 ID&gt; | all] -- 转储线程的堆栈以及 pc 信息up [n 帧] -- 向上移动线程的堆栈down [n 帧] -- 向下移动线程的堆栈kill &lt;线程 ID&gt; &lt;表达式&gt; -- 中止具有给定的异常对象的线程interrupt &lt;线程 ID&gt; -- 中断线程print &lt;表达式&gt; -- 输出表达式的值dump &lt;表达式&gt; -- 输出所有对象信息eval &lt;表达式&gt; -- 计算表达式的值（与 print 作用相同）set &lt;lvalue&gt; = &lt;表达式&gt; -- 为字段/变量/数组元素指定新值locals -- 输出当前堆栈帧中的所有本地变量classes -- 列出当前已知的类class &lt;类 ID&gt; -- 显示已命名类的详细信息methods &lt;类 ID&gt; -- 列出类的方法fields &lt;类 ID&gt; -- 列出类的字段threadgroups -- 列出线程组threadgroup &lt;名称&gt; -- 设置当前线程组stop in &lt;类 ID&gt;.&lt;方法&gt;[(参数类型,...)] -- 在方法中设置断点stop at &lt;类 ID&gt;:&lt;行&gt; -- 在行中设置断点clear &lt;类 ID&gt;.&lt;方法&gt;[(参数类型,...)] -- 清除方法中的断点clear &lt;类 ID&gt;:&lt;行&gt; -- 清除行中的断点clear -- 列出断点catch [uncaught|caught|all] &lt;类 ID&gt;|&lt;类模式&gt; -- 出现指定的异常时中断ignore [uncaught|caught|all] &lt;类 ID&gt;|&lt;类模式&gt; -- 对于指定的异常，取消 'catch'watch [access|all] &lt;类 ID&gt;.&lt;字段名&gt; -- 监视对字段的访问/修改unwatch [access|all] &lt;类 ID&gt;.&lt;字段名&gt; -- 停止监视对字段的访问/修改trace [go] methods [thread] -- 跟踪方法的进入和退出。 -- 除非指定 'go'，否则所有线程都将暂停trace [go] method exit | exits [thread] -- 跟踪当前方法的退出或所有方法的退出 -- 除非指定 'go'，否则所有线程都将暂停untrace [方法] -- 停止跟踪方法的进入和/或退出step -- 执行当前行step up -- 执行到当前方法返回其调用方stepi -- 执行当前指令next -- 跳过一行（跨过调用）cont -- 从断点处继续执行list [line number|method] -- 输出源代码use（或 sourcepath）[源文件路径] -- 显示或更改源路径exclude [&lt;类模式&gt;, ...|“无”] -- 不报告指定类的步骤或方法事件classpath -- 从目标 VM 输出类路径信息monitor &lt;命令&gt; -- 每次程序停止时执行命令monitor -- 列出监视器unmonitor &lt;监视器号&gt; -- 删除某个监视器read &lt;文件名&gt; -- 读取并执行某个命令文件lock &lt;表达式&gt; -- 输出对象的锁信息threadlocks [线程 ID] -- 输出线程的锁信息pop -- 弹出整个堆栈，且包含当前帧reenter -- 与 pop 作用相同，但重新进入当前帧redefine &lt;类 ID&gt; &lt;类文件名&gt; -- 重新定义类代码disablegc &lt;表达式&gt; -- 禁止对象的垃圾回收enablegc &lt;表达式&gt; -- 允许对象的垃圾回收!! -- 重复执行最后一个命令&lt;n&gt; &lt;命令&gt; -- 将命令重复执行 n 次# &lt;命令&gt; -- 放弃（不执行）help（或 ?） -- 列出命令version -- 输出版本信息exit（或 quit） -- 退出调试器&lt;类 ID&gt;: 带有软件包限定符的完整类名&lt;类模式&gt;: 带有前导或后缀通配符 (*) 的类名&lt;线程 ID&gt;: 'threads' 命令中所报告的线程号&lt;表达式&gt;: Java(TM) 编程语言表达式。支持大多数常见语法。可以将启动命令置于 "jdb.ini" 或 ".jdbrc" 之中（两者位于 user.home 或 user.dir 中） 有关JDB的使用详细介绍请参考官方文档。接下来我将用JDB调试Tomcat（以Tomcat7为例）下的应用来介绍下JDB的简单用法。 使用JDB进行调试，大概有下面几个步骤： 在服务器上创建setenv.bat文件，并输入如下内容，并将该文件放在Tomcat安装目录的bin目录下，并重启Tomcat； 1set CATALINA_OPTS="-agentlib:jdwp=transport=dt_socket,address=8787,server=y,suspend=n" 将应用系统的源码解压至某一目录，如src_dir1与src_dir2 在CLI下输入以下命令连接至服务器上的Tomcat 1jdb -connect com.sun.jdi.SocketAttach:hostname=localhost,port=8787,timeout=3000 -sourcepath src_dir1:src_dir2 这样就可以进入JDB的DEBUG环境了，你可以通过stop命令创建断点，通过next命令单行调试，通过step命令单步调试，通过step up命令返回至上层调用点等，具体使用网上一堆参考资料。 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[PhpStorm+Laravel_5.1开发环境搭建]]></title>
      <url>%2F2016%2F01%2F12%2FPhpStorm-Laravel-5-1%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
      <content type="text"><![CDATA[参数文档：Laravel Development using PhpStorm 在PhpStorm + Laravel5.1下无法为artisan创建【command line tool support】问题 现象：12345678ProblemFailed to parse output as xml: Error on line 4: Content is not allowed in prolog..Commandphp.exe C:\Users\Maxim.Kolmakov\PhpstormProjects\Laravel-5\artisan list --xmlOutput [ErrorException] The --xml option was deprecated in version 2.7 and will be removed in versi on 3.0. Use the --format option instead. 原因：Laravel 5.1版的Artisan的命令行的xml标志位已经被删除，详见Symfony的Git提交记录。 解决办法：2种 将Laravel降级为5.0版本 到目录[项目根目录]/vendor/symfony/console/Command下将如下两个文件还原回去：12HelpCommand.phpListCommand.php 2.phpstorm laravel live template 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[嵌套删除SQL引起的死锁问题分析]]></title>
      <url>%2F2015%2F12%2F20%2F%E5%B5%8C%E5%A5%97%E5%88%A0%E9%99%A4SQL%E5%BC%95%E8%B5%B7%E7%9A%84%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
      <content type="text"><![CDATA[问题背景应用系统后台有两个计划任务 每天1：00定时删除N天前的计划日志表数据 每隔5分钟统计AP终端在线用户数并更新计划日志表某一条记录的状态 错误日志123456789101112131415161718192021222324252627------------------------LATEST DETECTED DEADLOCK------------------------150914 3:00:12*** (1) TRANSACTION:TRANSACTION 209F80FE, ACTIVE 2 sec starting index readmysql tables in use 1, locked 1LOCK WAIT 2 lock struct(s), heap size 320, 1 row lock(s)MySQL thread id 241534, OS thread handle 0x2e5c, query id 2220277302 localhost 127.0.0.1 root UpdatingUPDATE T_BATCH_JOB_EXECUTION set START_TIME = '2015-09-14 03:00:06', END_TIME = '2015-09-14 03:00:10', STATUS = 'COMPLETED', CONTINUABLE = 'N', EXIT_CODE = 'COMPLETED', EXIT_MESSAGE = '', VERSION = 4, CREATE_TIME = '2015-09-14 03:00:06' where JOB_EXECUTION_ID = 435431*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F80FE lock_mode X locks rec but not gap waiting*** (2) TRANSACTION:TRANSACTION 209F7560, ACTIVE 7 sec fetching rows, thread declared inside InnoDB 130mysql tables in use 2, locked 21108 lock struct(s), heap size 77120, 52179 row lock(s), undo log entries 7455MySQL thread id 235617, OS thread handle 0xf10, query id 2220277303 localhost 127.0.0.1 root preparingdelete from t_batch_job_execution where job_instance_id in (select id from t_batch_plan_execution where due_time &lt;= '2015-09-07 00:00:00' )*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F7560 lock mode S locks rec but not gap*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F7560 lock_mode X locks rec but not gap waiting*** WE ROLL BACK TRANSACTION (1) 问题分析 mysql在执行【delete from T where … in select … from K …】的SQL时，会对K表的查询结果集添加共享锁【S锁】，以防止SQL执行过程中其它事务对K表进行变更操作，最终影响查询结果。可参考InnoDB存储引擎SQL语句加锁类型分析 【事务2】为”系统日志删除计划任务”，该事务涉及多个DELETE SQL，其中1234delete from t_batch_step_execution where job_execution_id in (select job_execution_id from t_batch_job_execution as job, t_batch_plan_execution as exec where job.job_instance_id = exec.id and exec.due_time &lt;= ? ) 会导致t_batch_job_execution表的某些记录被加上S锁，可从死锁日志中得到验证1*** (2) HOLDS THE LOCK(S):RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F7560 lock mode S locks rec but not gap 【事务1】的”5分钟终端统计任务”的SQL1UPDATE T_BATCH_JOB_EXECUTION set START_TIME = '2015-09-14 03:00:06', END_TIME = '2015-09-14 03:00:10', STATUS = 'COMPLETED', CONTINUABLE = 'N', EXIT_CODE = 'COMPLETED', EXIT_MESSAGE = '', VERSION = 4, CREATE_TIME = '2015-09-14 03:00:06' where JOB_EXECUTION_ID = 435431 需要对T_BATCH_JOB_EXECUTION表指定行申请加上排它锁【X锁】；在加【X锁】前，INNODB存储引擎会先隐式申请该行的意向排它锁【IX锁】；由于该行已经被【事务2】加上【S锁】，但是【IX锁】与【S锁】是兼容的，因此【事务1】对该行加【IX锁】成功，而【X锁】与【S锁】会冲突，因此【事务1】就处于等待【X锁】状态，可从死锁日志得到验证1*** (1) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F80FE lock_mode X locks rec but not gap waiting 【事务2】接下来执行SQL1delete from t_batch_job_execution where job_instance_id in (select id from t_batch_plan_execution where due_time &lt;= ? ) 需要申请【IX琐】(原理同上)、【X琐】,而由于指定行此时已经被【事务1】加上【IX锁】，由于而【IX锁】与【X锁】会冲突，因此【事务2】就处理申请等待【X锁】的状态，可从死锁日志得到验证1*** (2) WAITING FOR THIS LOCK TO BE GRANTED:RECORD LOCKS space id 101740 page no 388 n bits 240 index `PRIMARY` of table `emp`.`t_batch_job_execution` trx id 209F7560 lock_mode X locks rec but not gap waiting 解决方案对”系统日志删除计划任务”的相关SQL进行拆分，避免出现S锁的现象，即将1delete from t_batch_step_execution where job_execution_id in (select job_execution_id from t_batch_job_execution as job, t_batch_plan_execution as exec where job.job_instance_id = exec.id and exec.due_time &lt;= ? ) 拆分为两个SQL：121. select job_execution_id from t_batch_job_execution as job, t_batch_plan_execution as exec where job.job_instance_id = exec.id and exec.due_time &lt;= ? 2. delete from t_batch_step_execution where job_execution_id in ( ? ) 可以这样拆分的原因为：系统日志删除任务主要是删除N天前的数据，子查询的结果在短时间内是不会变化的。 参考资料 MySQL加锁处理分析 转载请注明出处：cloudnoter.com]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[历史文章]]></title>
      <url>%2F2015%2F12%2F20%2F%E5%8E%86%E5%8F%B2%E6%96%87%E7%AB%A0%2F</url>
      <content type="text"><![CDATA[说来惭愧，工作这么5年多，就只在CSDN上写了几个字，这些文章主要是学习笔记：CSDN上的文章]]></content>
    </entry>

    
  
  
</search>
